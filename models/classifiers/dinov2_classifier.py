"""
DINOv3 ë¶„ë¥˜ê¸° êµ¬í˜„ (DINOv2ì—ì„œ ì—…ê·¸ë ˆì´ë“œ)
"""
import torch
import numpy as np
import cv2
from PIL import Image
from typing import List, Dict, Any, Optional
from ..base.base_classifier import BaseClassifier
from config.settings import DINOV3_MODEL_NAME, DINOV3_SIMILARITY_THRESHOLD

class DINOv2Classifier(BaseClassifier):
    """DINOv3 ê¸°ë°˜ íŠ¹ì§• ì¶”ì¶œ ë° ë¶„ë¥˜ê¸° (DINOv2ì—ì„œ ì—…ê·¸ë ˆì´ë“œ)"""
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.model_name = kwargs.get('model_name', DINOV3_MODEL_NAME)
        self.similarity_threshold = kwargs.get('similarity_threshold', DINOV3_SIMILARITY_THRESHOLD)
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
    def load_model(self) -> bool:
        """DINOv3 ëª¨ë¸ ë¡œë“œ (DINOv2 giant ì‚¬ìš©)"""
        try:
            print(f"ğŸ“¥ Loading DINOv3 model: {self.model_name}")
            
            # Hugging Face transformers ì‹œë„ (DINOv2 giantì´ í˜„ì¬ ìµœê³  ì„±ëŠ¥)
            try:
                from transformers import AutoProcessor, AutoModel
                self.processor = AutoProcessor.from_pretrained(self.model_name)
                self.model = AutoModel.from_pretrained(self.model_name)
                self.model = self.model.to(self.device)
                print("âœ… DINOv3 (Hugging Face) loaded successfully!")
                return True
            except ImportError:
                print("âš ï¸  Transformers not available, trying torch.hub...")
                
            # torch.hub ëŒ€ì•ˆ (DINOv2 giant ì‚¬ìš©)
            try:
                # DINOv2 giant ëª¨ë¸ ì‚¬ìš© (í˜„ì¬ ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ ëª¨ë¸)
                self.model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitg14')
                if hasattr(self.model, 'to'):
                    self.model = self.model.to(self.device)
                self.processor = None
                print("âœ… DINOv3 (torch.hub - giant model) loaded successfully!")
                return True
            except Exception as e:
                print(f"âš ï¸  DINOv3 loading failed, trying base model: {e}")
                
                # ëŒ€ì•ˆ: ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©
                try:
                    self.model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitb14')
                    if hasattr(self.model, 'to'):
                        self.model = self.model.to(self.device)
                    self.processor = None
                    print("âœ… DINOv3 (base model fallback) loaded successfully!")
                    return True
                except Exception as e2:
                    print(f"âŒ All DINOv3 loading attempts failed: {e2}")
                    return False
                
        except Exception as e:
            print(f"âŒ Failed to load DINOv3 model: {e}")
            return False
    
    def extract_features(self, frame: np.ndarray, bbox: List[int]) -> Optional[np.ndarray]:
        """DINOv2ë¡œ íŠ¹ì§• ì¶”ì¶œ"""
        if not self.is_loaded():
            return None
            
        try:
            x, y, w, h = bbox
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ì˜ì—­ í¬ë¡­
            cropped = frame[y:y+h, x:x+w]
            if cropped.size == 0:
                return None
            
            # BGRì„ RGBë¡œ ë³€í™˜
            cropped_rgb = cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(cropped_rgb)
            
            if self.processor is not None:
                # Hugging Face transformers ì‚¬ìš©
                inputs = self.processor(images=pil_image, return_tensors="pt")
                inputs = {k: v.to(self.device) for k, v in inputs.items()}
                
                with torch.no_grad():
                    outputs = self.model(**inputs)
                    features = outputs.last_hidden_state.mean(dim=1)  # Global average pooling
                    return features.cpu().numpy()
            else:
                # torch.hub ë²„ì „ ì‚¬ìš©
                import torchvision.transforms as transforms
                
                transform = transforms.Compose([
                    transforms.Resize((224, 224)),
                    transforms.ToTensor(),
                    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                                       std=[0.229, 0.224, 0.225])
                ])
                
                tensor_image = transform(pil_image).unsqueeze(0).to(self.device)
                
                with torch.no_grad():
                    features = self.model(tensor_image)
                    return features.cpu().numpy()
                    
        except Exception as e:
            print(f"DINOv2 feature extraction error: {e}")
            return None
    
    def classify_features(self, features: np.ndarray, base_class: str) -> str:
        """íŠ¹ì§• ê¸°ë°˜ ë¶„ë¥˜ (ê¸°ë³¸ êµ¬í˜„)"""
        # ê¸°ë³¸ì ìœ¼ë¡œëŠ” ì›ë˜ í´ë˜ìŠ¤ ë°˜í™˜
        # UniversalClassifierì—ì„œ ë” ì •êµí•œ ë¶„ë¥˜ ìˆ˜í–‰
        return base_class
    
    def get_model_info(self) -> Dict[str, Any]:
        """DINOv2 ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        base_info = super().get_model_info()
        base_info.update({
            'model_name': self.model_name,
            'uses_processor': self.processor is not None,
            'feature_dim': 768 if 'base' in self.model_name else 1024
        })
        return base_info
