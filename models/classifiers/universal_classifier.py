"""
ë²”ìš© ë¶„ë¥˜ê¸° êµ¬í˜„ (ê¸°ì¡´ UniversalCustomLabelClassifier ë¦¬íŒ©í† ë§)
"""
import numpy as np
import cv2
import pickle
from typing import List, Dict, Any, Optional
from sklearn.cluster import KMeans
from sklearn.metrics.pairwise import cosine_similarity
from ..base.base_classifier import BaseClassifier

class UniversalClassifier(BaseClassifier):
    """DINOv2 íŠ¹ì§•ì„ í™œìš©í•œ ë²”ìš© ì»¤ìŠ¤í…€ ë¼ë²¨ ë¶„ë¥˜ê¸°"""
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.label_features = {}  # ë¼ë²¨ë³„ íŠ¹ì§• ë°ì´í„°ë² ì´ìŠ¤
        self.feature_clusters = {}  # ë¼ë²¨ë³„ í´ëŸ¬ìŠ¤í„°
        self.min_samples_for_clustering = kwargs.get('min_samples_for_clustering', 3)
        
        # DINOv2 ë¶„ë¥˜ê¸°ì™€ ì—°ë™
        self.feature_extractor = None
        
    def load_model(self) -> bool:
        """ëª¨ë¸ ë¡œë“œ (íŠ¹ì§• ì¶”ì¶œê¸° ì„¤ì •)"""
        # UniversalClassifierëŠ” ë³„ë„ ëª¨ë¸ì´ ì•„ë‹ˆë¼ íŠ¹ì§• ì¶”ì¶œê¸°ë¥¼ ì‚¬ìš©
        return True
    
    def set_feature_extractor(self, extractor):
        """íŠ¹ì§• ì¶”ì¶œê¸° ì„¤ì •"""
        self.feature_extractor = extractor
    
    def extract_features(self, frame: np.ndarray, bbox: List[int]) -> Optional[np.ndarray]:
        """íŠ¹ì§• ì¶”ì¶œ (íŠ¹ì§• ì¶”ì¶œê¸° ìœ„ì„)"""
        if self.feature_extractor:
            return self.feature_extractor.extract_features(frame, bbox)
        return None
    
    def classify_features(self, features: np.ndarray, base_class: str) -> str:
        """í•™ìŠµëœ íŒ¨í„´ì„ ê¸°ë°˜ìœ¼ë¡œ ì„¸ë¶€ ë¶„ë¥˜"""
        if features is None:
            return base_class
        
        features_flat = features.flatten()
        best_label = base_class
        best_similarity = 0
        
        # ëª¨ë“  í•™ìŠµëœ ë¼ë²¨ì— ëŒ€í•´ ìœ ì‚¬ë„ ê³„ì‚°
        for label, cluster_info in self.feature_clusters.items():
            if 'centroids' in cluster_info:
                for centroid in cluster_info['centroids']:
                    similarity = cosine_similarity([features_flat], [centroid])[0][0]
                    
                    if similarity > best_similarity and similarity > self.similarity_threshold:
                        best_similarity = similarity
                        best_label = label
        
        # ìœ ì‚¬í•œ íŒ¨í„´ì„ ì°¾ì•˜ìœ¼ë©´ ë” êµ¬ì²´ì ì¸ ë¼ë²¨ ì œì•ˆ
        if best_label != base_class and best_similarity > self.similarity_threshold:
            confidence = best_similarity * 100
            print(f"ğŸ¯ Universal classifier: {base_class} â†’ {best_label} (ì‹ ë¢°ë„: {confidence:.1f}%)")
            return best_label
        
        return base_class
    
    def learn_from_annotations(self, video_path: str, annotations: List[Dict[str, Any]]) -> bool:
        """ìˆ˜ë™ ë¼ë²¨ë§ ë°ì´í„°ì—ì„œ íŒ¨í„´ í•™ìŠµ"""
        if not self.feature_extractor:
            print("âš ï¸ Feature extractor not set")
            return False
            
        print("ğŸ§  Universal classifier íŒ¨í„´ í•™ìŠµ ì‹œì‘...")
        print("ğŸ—‘ï¸ ê¸°ì¡´ í•™ìŠµëœ íŒ¨í„´ ì´ˆê¸°í™”...")
        
        # ê¸°ì¡´ íŒ¨í„´ ë°ì´í„° ì´ˆê¸°í™”
        self.label_features = {}
        self.feature_clusters = {}
        
        if not annotations:
            print("âš ï¸ ìˆ˜ë™ ë¼ë²¨ë§ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        try:
            cap = cv2.VideoCapture(video_path)
            fps = cap.get(cv2.CAP_PROP_FPS)
            
            learned_labels = set()
            
            for ann in annotations:
                label = ann['label']
                frame_time = float(ann['frame'])
                bbox = ann['bbox']
                
                # í•´ë‹¹ í”„ë ˆì„ìœ¼ë¡œ ì´ë™
                frame_number = int(frame_time * fps)
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)
                ret, frame = cap.read()
                
                if not ret:
                    continue
                
                # íŠ¹ì§• ì¶”ì¶œ
                features = self.extract_features(frame, bbox)
                
                if features is not None:
                    if label not in self.label_features:
                        self.label_features[label] = []
                    
                    self.label_features[label].append(features.flatten())
                    learned_labels.add(label)
            
            cap.release()
            
            # ê° ë¼ë²¨ë³„ë¡œ í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰
            for label in learned_labels:
                self._create_label_clusters(label)
            
            print(f"âœ… í•™ìŠµ ì™„ë£Œ: {len(learned_labels)}ê°œ ë¼ë²¨ ({sum(len(features) for features in self.label_features.values())}ê°œ ìƒ˜í”Œ)")
            return True
            
        except Exception as e:
            print(f"âŒ íŒ¨í„´ í•™ìŠµ ì˜¤ë¥˜: {e}")
            return False
    
    def _create_label_clusters(self, label: str):
        """ë¼ë²¨ë³„ íŠ¹ì§• í´ëŸ¬ìŠ¤í„° ìƒì„±"""
        if label not in self.label_features or len(self.label_features[label]) < self.min_samples_for_clustering:
            print(f"ğŸ“Š {label}: ìƒ˜í”Œ ë¶€ì¡±ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë§ ê±´ë„ˆëœ€ ({len(self.label_features.get(label, []))}ê°œ)")
            return
        
        try:
            features = np.array(self.label_features[label])
            
            # ì ì‘ì  í´ëŸ¬ìŠ¤í„° ìˆ˜ ê²°ì •
            n_samples = len(features)
            n_clusters = min(3, max(1, n_samples // 2))  # ìµœëŒ€ 3ê°œ í´ëŸ¬ìŠ¤í„°
            
            if n_clusters > 1:
                kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init='auto')
                cluster_labels = kmeans.fit_predict(features)
                
                self.feature_clusters[label] = {
                    'kmeans': kmeans,
                    'centroids': kmeans.cluster_centers_,
                    'labels': cluster_labels,
                    'features': features
                }
                
                print(f"ğŸ“Š {label}: {n_clusters}ê°œ í´ëŸ¬ìŠ¤í„° ìƒì„± ({n_samples}ê°œ ìƒ˜í”Œ)")
            else:
                # í´ëŸ¬ìŠ¤í„°ê°€ 1ê°œë©´ í‰ê·  íŠ¹ì§•ë§Œ ì €ì¥
                self.feature_clusters[label] = {
                    'centroids': [np.mean(features, axis=0)],
                    'features': features
                }
                print(f"ğŸ“Š {label}: ë‹¨ì¼ í´ëŸ¬ìŠ¤í„° ìƒì„± ({n_samples}ê°œ ìƒ˜í”Œ)")
                
        except Exception as e:
            print(f"âŒ {label} í´ëŸ¬ìŠ¤í„°ë§ ì˜¤ë¥˜: {e}")
    
    def get_learned_patterns_info(self) -> Dict[str, Any]:
        """í•™ìŠµëœ ë¼ë²¨ ì •ë³´ ë°˜í™˜"""
        info = {}
        for label, features in self.label_features.items():
            cluster_count = len(self.feature_clusters.get(label, {}).get('centroids', []))
            info[label] = {
                'sample_count': len(features),
                'cluster_count': cluster_count,
                'has_clustering': cluster_count > 1
            }
        return info
    
    def save_patterns(self, filepath: str) -> bool:
        """í•™ìŠµëœ íŒ¨í„´ì„ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            with open(filepath, 'wb') as f:
                pickle.dump({
                    'label_features': self.label_features,
                    'feature_clusters': self.feature_clusters,
                    'similarity_threshold': self.similarity_threshold
                }, f)
            return True
        except Exception as e:
            print(f"íŒ¨í„´ ì €ì¥ ì˜¤ë¥˜: {e}")
            return False
    
    def load_patterns(self, filepath: str) -> bool:
        """ì €ì¥ëœ íŒ¨í„´ì„ ë¡œë“œ"""
        try:
            with open(filepath, 'rb') as f:
                data = pickle.load(f)
                self.label_features = data['label_features']
                self.feature_clusters = data['feature_clusters']
                self.similarity_threshold = data['similarity_threshold']
            return True
        except Exception as e:
            print(f"íŒ¨í„´ ë¡œë“œ ì˜¤ë¥˜: {e}")
            return False
    
    def has_learned_patterns(self) -> bool:
        """í•™ìŠµëœ íŒ¨í„´ì´ ìˆëŠ”ì§€ í™•ì¸"""
        return len(self.label_features) > 0
    
    def classify_as_custom_object(self, features: np.ndarray) -> Optional[str]:
        """íŠ¹ì§•ì„ ì‚¬ìš©í•˜ì—¬ í•™ìŠµëœ ì»¤ìŠ¤í…€ ê°ì²´ì¸ì§€ íŒë³„"""
        if features is None:
            print("âŒ Features is None, cannot classify")
            return None
            
        if not self.has_learned_patterns():
            print("âŒ No learned patterns available")
            return None
        
        features_flat = features.flatten()
        best_label = None
        best_similarity = 0
        all_similarities = []
        
        print(f"ğŸ” Checking against {len(self.feature_clusters)} learned labels (threshold: {self.similarity_threshold})")
        
        # ëª¨ë“  í•™ìŠµëœ ë¼ë²¨ì— ëŒ€í•´ ìœ ì‚¬ë„ ê³„ì‚°
        for label, cluster_info in self.feature_clusters.items():
            if 'centroids' in cluster_info:
                max_sim_for_label = 0
                for i, centroid in enumerate(cluster_info['centroids']):
                    similarity = cosine_similarity([features_flat], [centroid])[0][0]
                    max_sim_for_label = max(max_sim_for_label, similarity)
                    
                    if similarity > best_similarity:
                        best_similarity = similarity
                        if similarity > self.similarity_threshold:
                            best_label = label
                
                all_similarities.append((label, max_sim_for_label))
                print(f"  ğŸ“Š {label}: {max_sim_for_label:.3f} {'âœ…' if max_sim_for_label > self.similarity_threshold else 'âŒ'}")
        
        # ì„ê³„ê°’ì„ ë„˜ëŠ” ìœ ì‚¬ë„ë¥¼ ê°€ì§„ ë¼ë²¨ì´ ìˆìœ¼ë©´ ë°˜í™˜
        if best_label and best_similarity > self.similarity_threshold:
            confidence = best_similarity * 100
            print(f"ğŸ¯ Custom object MATCH: {best_label} (ì‹ ë¢°ë„: {confidence:.1f}%)")
            return best_label
        else:
            print(f"âŒ No match found (best: {best_similarity:.3f}, threshold: {self.similarity_threshold})")
            return None
    
    def get_learned_labels(self) -> List[str]:
        """í•™ìŠµëœ ë¼ë²¨ ëª©ë¡ ë°˜í™˜"""
        return list(self.label_features.keys())