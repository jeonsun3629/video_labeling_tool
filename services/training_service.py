"""
í›ˆë ¨ ì„œë¹„ìŠ¤
"""
import os
import cv2
import shutil
from typing import List, Dict, Any, Optional
from pathlib import Path
from ultralytics import YOLO
from .model_manager import ModelManager
from config.settings import UPLOAD_FOLDER, DEFAULT_EPOCHS, DEFAULT_BATCH_SIZE, DEFAULT_IMAGE_SIZE, BASE_DIR

class TrainingService:
    """ëª¨ë¸ í›ˆë ¨ ê´€ë ¨ ì„œë¹„ìŠ¤"""
    
    def __init__(self, model_manager: ModelManager):
        self.model_manager = model_manager
    
    def cleanup_previous_training(self) -> None:
        """ì´ì „ í›ˆë ¨ ê²°ê³¼ ì •ë¦¬"""
        try:
            training_base_dir = Path(BASE_DIR) / 'custom_training'
            
            if training_base_dir.exists():
                print("ğŸ§¹ ì´ì „ í›ˆë ¨ ê²°ê³¼ ì •ë¦¬ ì¤‘...")
                
                # custom_training ë””ë ‰í„°ë¦¬ ì „ì²´ ì‚­ì œ
                shutil.rmtree(training_base_dir)
                print("âœ… ì´ì „ í›ˆë ¨ ê²°ê³¼ ì •ë¦¬ ì™„ë£Œ")
            
            # ìƒˆë¡œìš´ ë””ë ‰í„°ë¦¬ ìƒì„±
            training_base_dir.mkdir(parents=True, exist_ok=True)
            
        except Exception as e:
            print(f"âš ï¸ í›ˆë ¨ ê²°ê³¼ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ (ê³„ì† ì§„í–‰): {e}")
        
    def train_model(self, video_path: str, annotations: List[Dict[str, Any]], 
                   epochs: int = DEFAULT_EPOCHS, accumulated_data: Optional[List] = None) -> Dict[str, Any]:
        """ì»¤ìŠ¤í…€ ëª¨ë¸ í›ˆë ¨"""
        try:
            # ì´ì „ í›ˆë ¨ ê²°ê³¼ ì •ë¦¬
            self.cleanup_previous_training()
            
            # í•™ìŠµ ë°ì´í„° ì¤€ë¹„
            training_dir = os.path.join(UPLOAD_FOLDER, 'training_data')
            prep_result = self.prepare_training_data(video_path, annotations, training_dir, accumulated_data)
            
            if not prep_result['success']:
                return {'success': False, 'error': prep_result['error']}
            
            # YOLO ëª¨ë¸ í›ˆë ¨
            train_result = self.train_yolo_model(prep_result['dataset_path'], epochs)
            
            if train_result['success']:
                # ê²°ê³¼ì— ì¤€ë¹„ ë‹¨ê³„ ì •ë³´ ì¶”ê°€
                train_result.update({
                    'images_count': prep_result['images_count'],
                    'total_annotations': prep_result['total_annotations'],
                    'classes': prep_result['classes'],
                    'current_annotations': prep_result['current_annotations']
                })
            
            return train_result
            
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def prepare_training_data(self, video_path: str, annotations: List[Dict[str, Any]], 
                            output_dir: str, accumulated_data: Optional[List] = None) -> Dict[str, Any]:
        """ìˆ˜ë™ ë¼ë²¨ë§ ë°ì´í„°ë¥¼ YOLO í•™ìŠµ í¬ë§·ìœ¼ë¡œ ë³€í™˜"""
        try:
            os.makedirs(output_dir, exist_ok=True)
            
            # ì´ë¯¸ì§€ì™€ ë¼ë²¨ í´ë” ìƒì„±
            images_dir = os.path.join(output_dir, 'images')
            labels_dir = os.path.join(output_dir, 'labels')
            os.makedirs(images_dir, exist_ok=True)
            os.makedirs(labels_dir, exist_ok=True)
            
            cap = cv2.VideoCapture(video_path)
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            
            # í˜„ì¬ ìˆ˜ë™ ë¼ë²¨ë§ ë°ì´í„°
            current_manual_annotations = [ann for ann in annotations if ann.get('source') == 'manual' or ann.get('source') is None]
            
            # ëˆ„ì  ë°ì´í„°ì™€ í˜„ì¬ ë°ì´í„° ë³‘í•©
            all_manual_annotations = current_manual_annotations.copy()
            if accumulated_data:
                all_manual_annotations.extend(accumulated_data)
            
            # ê³ ìœ  ë¼ë²¨ ì¶”ì¶œ ë° í´ë˜ìŠ¤ ë§¤í•‘ ìƒì„±
            unique_labels = list(set([ann['label'] for ann in all_manual_annotations]))
            class_mapping = {label: i for i, label in enumerate(unique_labels)}
            
            print(f"Total training annotations: {len(all_manual_annotations)}")
            print(f"Classes: {unique_labels}")
            
            # classes.txt íŒŒì¼ ìƒì„±
            with open(os.path.join(output_dir, 'classes.txt'), 'w') as f:
                for label in unique_labels:
                    f.write(f"{label}\n")
            
            # í˜„ì¬ ë¹„ë””ì˜¤ì˜ ì–´ë…¸í…Œì´ì…˜ì„ ì‹œê°„ë³„ë¡œ ê·¸ë£¹í™”
            time_annotations = {}
            for ann in current_manual_annotations:
                frame_time = float(ann['frame'])
                if frame_time not in time_annotations:
                    time_annotations[frame_time] = []
                time_annotations[frame_time].append(ann)
            
            saved_frames = 0
            frame_count = 0
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                current_time = frame_count / fps
                
                # í˜„ì¬ ì‹œê°„ì— í•´ë‹¹í•˜ëŠ” ì–´ë…¸í…Œì´ì…˜ ì°¾ê¸°
                matching_annotations = []
                for time_key, anns in time_annotations.items():
                    if abs(time_key - current_time) < (1.0 / fps):
                        matching_annotations.extend(anns)
                
                if matching_annotations:
                    # í”„ë ˆì„ ì €ì¥
                    frame_filename = f"frame_{saved_frames:06d}.jpg"
                    frame_path = os.path.join(images_dir, frame_filename)
                    cv2.imwrite(frame_path, frame)
                    
                    # YOLO í¬ë§· ë¼ë²¨ íŒŒì¼ ìƒì„±
                    label_filename = f"frame_{saved_frames:06d}.txt"
                    label_path = os.path.join(labels_dir, label_filename)
                    
                    with open(label_path, 'w') as f:
                        for ann in matching_annotations:
                            x, y, w, h = ann['bbox']
                            label = ann['label']
                            
                            if label in class_mapping:
                                # YOLO í¬ë§·ìœ¼ë¡œ ë³€í™˜ (normalized coordinates)
                                x_center = (x + w/2) / width
                                y_center = (y + h/2) / height
                                norm_width = w / width
                                norm_height = h / height
                                
                                class_id = class_mapping[label]
                                f.write(f"{class_id} {x_center:.6f} {y_center:.6f} {norm_width:.6f} {norm_height:.6f}\n")
                    
                    saved_frames += 1
                
                frame_count += 1
            
            cap.release()
            
            # ëˆ„ì  ë°ì´í„°ê°€ ìˆë‹¤ë©´ ì¶”ê°€ë¡œ ì²˜ë¦¬
            if accumulated_data:
                self._copy_accumulated_data(accumulated_data, images_dir, labels_dir, class_mapping, saved_frames)
            
            # dataset.yaml íŒŒì¼ ìƒì„±
            yaml_content = f"""
path: {output_dir}
train: images
val: images

nc: {len(unique_labels)}
names: {unique_labels}
"""
            with open(os.path.join(output_dir, 'dataset.yaml'), 'w') as f:
                f.write(yaml_content)
            
            return {
                'success': True,
                'images_count': saved_frames,
                'total_annotations': len(all_manual_annotations),
                'classes': unique_labels,
                'dataset_path': os.path.join(output_dir, 'dataset.yaml'),
                'current_annotations': current_manual_annotations
            }
            
        except Exception as e:
            print(f"Training data preparation error: {e}")
            return {'success': False, 'error': str(e)}
    
    def _copy_accumulated_data(self, accumulated_data: List[Dict[str, Any]], images_dir: str, 
                             labels_dir: str, class_mapping: Dict[str, int], start_idx: int):
        """ëˆ„ì ëœ í•™ìŠµ ë°ì´í„°ë¥¼ ìƒˆ í•™ìŠµ í´ë”ì— ë³µì‚¬"""
        try:
            for i, ann in enumerate(accumulated_data):
                if 'image_path' in ann and os.path.exists(ann['image_path']):
                    # ì´ë¯¸ì§€ ë³µì‚¬
                    new_image_name = f"accumulated_{start_idx + i:06d}.jpg"
                    new_image_path = os.path.join(images_dir, new_image_name)
                    shutil.copy2(ann['image_path'], new_image_path)
                    
                    # ë¼ë²¨ íŒŒì¼ ìƒì„±
                    label_filename = f"accumulated_{start_idx + i:06d}.txt"
                    label_path = os.path.join(labels_dir, label_filename)
                    
                    with open(label_path, 'w') as f:
                        label = ann['label']
                        if label in class_mapping:
                            x, y, w, h = ann['bbox']
                            # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° ì •ë³´ê°€ ìˆë‹¤ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ í˜„ì¬ ë¹„ë””ì˜¤ í¬ê¸° ì‚¬ìš©
                            img_width = ann.get('image_width', 640)
                            img_height = ann.get('image_height', 480)
                            
                            x_center = (x + w/2) / img_width
                            y_center = (y + h/2) / img_height
                            norm_width = w / img_width
                            norm_height = h / img_height
                            
                            class_id = class_mapping[label]
                            f.write(f"{class_id} {x_center:.6f} {y_center:.6f} {norm_width:.6f} {norm_height:.6f}\n")
        except Exception as e:
            print(f"Error copying accumulated data: {e}")
    
    def train_yolo_model(self, dataset_path: str, epochs: int = DEFAULT_EPOCHS) -> Dict[str, Any]:
        """YOLO ëª¨ë¸ í›ˆë ¨"""
        try:
            print(f"ğŸš€ Enhanced YOLO training starting with {epochs} epochs...")
            
            # ë² ì´ìŠ¤ ëª¨ë¸ì—ì„œ ì‹œì‘
            model = YOLO('yolov8n.pt')
            
            # í•™ìŠµ ì‹¤í–‰ (ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ íŒŒë¼ë¯¸í„° ì¡°ì •)
            results = model.train(
                data=dataset_path,
                epochs=epochs,
                imgsz=DEFAULT_IMAGE_SIZE,
                batch=DEFAULT_BATCH_SIZE,
                lr0=0.001,  # ì´ˆê¸° í•™ìŠµë¥ 
                lrf=0.01,  # ìµœì¢… í•™ìŠµë¥ 
                momentum=0.937,
                weight_decay=0.0005,
                warmup_epochs=3,
                warmup_momentum=0.8,
                patience=15,
                close_mosaic=10,
                mixup=0.1,
                copy_paste=0.1,
                degrees=10.0,
                translate=0.1,
                scale=0.9,
                shear=2.0,
                perspective=0.0001,
                flipud=0.5,
                fliplr=0.5,
                mosaic=1.0,
                save=True,
                project='custom_training',
                name='custom_model',
                exist_ok=True,
                pretrained=True,
                optimizer='AdamW',
                verbose=True,
                val=True,
                plots=True,
                save_period=10
            )
            
            # í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ
            if hasattr(results, 'save_dir') and results.save_dir:
                best_model_path = results.save_dir / 'weights' / 'best.pt'
                model_path = str(best_model_path)
            else:
                # ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©
                model_path = 'custom_training/custom_model/weights/best.pt'
            
            print(f"âœ… Enhanced YOLO training completed! Model saved at: {model_path}")
            
            # JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í›ˆë ¨ ê²°ê³¼ ì •ë³´ë§Œ ì¶”ì¶œ
            training_info = {
                'model_path': model_path,
                'epochs_completed': epochs,
                'save_dir': str(results.save_dir) if hasattr(results, 'save_dir') else None
            }
            
            # í›ˆë ¨ ë©”íŠ¸ë¦­ì´ ìˆë‹¤ë©´ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ
            try:
                if hasattr(results, 'results_dict'):
                    # ê¸°ë³¸ ë©”íŠ¸ë¦­ ì •ë³´ ì¶”ì¶œ
                    metrics = {}
                    results_dict = results.results_dict
                    for key, value in results_dict.items():
                        if isinstance(value, (int, float, str, bool, list)):
                            metrics[key] = value
                        elif hasattr(value, 'item'):  # torch.Tensor ë“±
                            try:
                                metrics[key] = value.item()
                            except:
                                metrics[key] = str(value)
                        else:
                            metrics[key] = str(value)
                    training_info['metrics'] = metrics
                
                # ê°„ë‹¨í•œ í†µê³„ ì •ë³´
                if hasattr(results, 'speed'):
                    training_info['training_speed'] = str(results.speed)
                    
            except Exception as e:
                print(f"âš ï¸ Could not extract training metrics: {e}")
                training_info['metrics_error'] = str(e)
            
            return {
                'success': True,
                'model_path': model_path,
                'training_info': training_info
            }
            
        except Exception as e:
            print(f"âŒ Enhanced training error: {e}")
            return {'success': False, 'error': str(e)}
